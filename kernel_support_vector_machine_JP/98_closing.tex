% TeX source
%
% Author: Tetsuya Ishikawa <tiskw111@gmail.com>
% Date  : January 20, 2020
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SOURCE START %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

本文書は，SVMという実用的な機械学習のツールを詳細に解説しつつ，
同時に関数解析の効用を読者に理解して頂こうと，
著者なりに試みた結果なのですが，いかがでしたでしょうか．

本文書におけるSVMの説明の大部分は赤穂\cite{Akaho2008}にしたがっています．
カーネル回帰の説明は私のオリジナルによる部分が多いですが，
関数空間の導入部分は手抜きが甚だしいと言わざるを得ません．
関数解析に興味ある読者は関数解析学の成書を参照して下さい．
私の知る範囲での関数解析学の良書として，
Jost \cite{Jost2005}や堀内ら\cite{Horiuchi2005}を挙げておきます．

また，本文書ではK-SVMに主眼をおいたため，実は一般的でないアプローチでSVMを導入しています．
一般的なアプローチ（マージン最適化）は様々な文献で紹介されていますので，興味のある読者はそちらをご参照下さい．
代表的な参考書としてはBishop\cite{Bishop2010}を挙げておきます．

再生核Hilbert空間についても，本文書では触れませんでした．
カーネル関数の設計に興味のある読者は，ぜひ触れてみると良いと思います．

本文書で紹介した内容の発展として，RFF (\textit{Random Fourier Features}) あるいは
ORF (\textit{Orthogonal Random Features}) によるカーネル関数の有限次元化が挙げられます．
カーネル法の限界のひとつに，学習に必要な計算量が学習データ数に応じて多項式的に増加してしまうという点があります．
これは，カーネル法はビッグデータを扱えないことを意味しており，無限の自由度を手にした代償とも言えるでしょう．
この問題を解消するために，RFFやORFではカーネル関数を適切な次数で有限近似し，
カーネルの自由度を活かしつつ計算量を抑えることで高速化を実現しています．
興味ある読者は是非Rahimi~\textit{et al.}\cite{Rahimi2007}，Yu~\textit{et al.}\cite{Yu2016}をご参照下さい．
本文書の知識で十分に読み進められると思います．

最後に，Toyota Research Institute Advanced Development, Inc. の乙部成史くんには
本文書の誤植をいくつも指摘して頂きました．この場を借りて厚く御礼申し上げます．
また，私の数学的活動は，2017年に逝去された恩師，山下弘一郎先生や，
大学および大学院で私の指導教官を担当して下さった早川朋久准教授をはじめ，
数学で私と関わりを持ったすべての方々のおかげで成り立っています．
そして，数学的活動の以前に，そもそも私の生は両親によって与えられ，妻によって支えられています．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SOURCE FINISH %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% vim: expandtab shiftwidth=4 tabstop=4 filetype=tex
