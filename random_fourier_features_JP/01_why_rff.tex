% TeX source
%
% Author: Tetsuya Ishikawa <tiskw111@gmail.com>
% Date  : March 01, 2020
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SOURCE START %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

機械学習におけるクラス分類問題を解く手法のひとつとして，カーネルサポートベクターマシンと呼ばれる手法がある．
これは通常のサポートベクターマシン（ここではこれを線形サポートベクターマシンと呼ぶことにしよう）にカーネル法を適用する
ことで柔軟性を格段に向上させたものであり，現在でも現役で使用されている，カーネル法の応用例のひとつでもある．
しかし，カーネルサポートベクターマシンには，学習や推論にかかる時間が学習データ数に多項式的に比例してしまうという決定的な弱点がある．
具体的には，学習データの数を$N$とすると，学習に要するステップ数は$O(N^3)$，推論に要するステップ数は$O(N)$である．
繰り返しになるが$N$は学習データの数である．これは，データの質よりも量の多さをよしとする機械学習の分野において，
致命的とも言える弱点である．この恐しさがお分かり頂けるであろうか？

想像して頂きたい．何らかのクラス分類器を作成したところ，性能があまり出なかったとしよう．
そうなったとき，学習データセットの拡充は間違いなく優先度の高い検討事項である．
しかし，先に述べた通り，カーネルサポートベクターマシンの場合は学習データの数を増やせば増やすほど
学習や推論にかかる時間が増えてしまう．
学習時間が増えるのはまだ許容範囲内であろうが，推論の時間まで増加してしまうのは許容し難いのではないだろうか．
もちろんケースバイケースではあるのだが，実応用では推論時間の上限は事前に決められており，また推論を行うデバイスも
変更できない場合が多く，推論の計算量の増加は致命的となるケースが多い．
つまり，カーネルサポートベクターマシンの場合は安易に学習データセットの追加ができないのである．

ちなみに，この弱点は線形サポートベクターマシンでは起こりにくい．
線形のサポートベクターマシンの場合，少なくとも推論時間は学習データセットの数によらず一定である．
つまり，この弱点はカーネル法によって高い柔軟性を得たことに由来するものなのである．
とは言え，線形サポートベクターマシンでは性能が出ないケースが多いのも事実であるから，
何とかしてカーネルサポートベクターマシンを高速化し，大量の学習データセットを適用したいものである．

この弱点を解消するために考え出されたのが，カーネル関数の有限次元近似であり，その中で最も成功しているのがRFFである．

これをキチンと説明するために，まずはカーネル法について簡単にご説明していこう．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SOURCE FINISH %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% vim: expandtab tabstop=4 shiftwidth=4 fdm=marker
